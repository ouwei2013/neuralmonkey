[main]
name="Configurations of Hierarchical Attention Captioning"
tf_manager=<tf_manager>
output="tests/outputs/hier-multiattention"
overwrite_output_dir=True
epochs=1
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner_hier_noshare_nosentinel>, <runner_hier_share_nosentinel>, <runner_hier_share_sentinel>, <runner_hier_noshare_sentinel>]
postprocess=None
evaluation=[("target_hier_noshare_nosentinel", "target", evaluators.BLEU)]
logging_period=1
validation_period=5
test_datasets=[<val_data>]
random_seed=1234

[batch_scheme]
class=dataset.BatchingScheme
bucket_boundaries=[5, 10, 15, 20, 25]
bucket_batch_sizes=[5, 4, 3, 2, 1, 1]
ignore_series=["images"]

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1

[image_reader]
class=readers.image_reader.image_reader
prefix="tests/data/flickr30k"
pad_h=32
pad_w=32
mode="RGB"
channels=3

[train_data]
class=dataset.load
series=["source", "target", "images"]
data=["tests/data/flickr30k/train.en", "tests/data/flickr30k/train.de", ("tests/data/flickr30k/train_images.txt", <image_reader>)]
batching=<batch_scheme>

[val_data]
class=dataset.load
series=["source", "target", "images"]
data=["tests/data/flickr30k/val.en", "tests/data/flickr30k/val.de", ("tests/data/flickr30k/val_images.txt", <image_reader>)]
batching=<batch_scheme>

[imagenet]
class=encoders.cnn_encoder.CNNEncoder
name="cnn"
data_id="images"
batch_normalize=True
image_height=32
image_width=32
pixel_dim=3
convolutions=[("C", 3, 1, "valid", 4),  ("M", 2, 2, "same"), ("M", 2, 2, "same")]

[encoder_vocabulary]
class=vocabulary.from_wordlist
path="tests/data/encoder_vocab.tsv"

[encoder]
class=encoders.recurrent.SentenceEncoder
name="sentence_encoder"
rnn_size=4
max_input_len=3
embedding_size=2
dropout_keep_prob=0.5
data_id="source"
vocabulary=<encoder_vocabulary>

[decoder_vocabulary]
class=vocabulary.from_wordlist
path="tests/data/decoder_vocab.tsv"

[enc_attention]
class=attention.Attention
name="enc_attention"
state_size=3
encoder=<encoder>

[img_attention]
class=attention.Attention
name="img_attention"
state_size=2
encoder=<imagenet>

[hier_noshare_nosentinel]
class=attention.combination.HierarchicalMultiAttention
name="wrapper_hnn"
attentions=[<enc_attention>, <img_attention>]
attention_state_size=5
use_sentinels=False
share_attn_projections=False

[decoder_hier_noshare_nosentinel]
class=decoders.decoder.Decoder
name="decoder_hier_noshare_nosentinel"
encoders=[<encoder>, <imagenet>]
attentions=[<hier_noshare_nosentinel>]
rnn_size=2
embedding_size=3
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[hier_share_nosentinel]
class=attention.combination.HierarchicalMultiAttention
name="wrapper_hsn"
attentions=[<enc_attention>, <img_attention>]
attention_state_size=5
use_sentinels=False
share_attn_projections=True

[decoder_hier_share_nosentinel]
class=decoders.decoder.Decoder
name="decoder_hier_share_nosentinel"
encoders=[<encoder>, <imagenet>]
attentions=[<hier_share_nosentinel>]
rnn_size=2
embedding_size=3
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[hier_share_sentinel]
class=attention.combination.HierarchicalMultiAttention
name="wrapper_hss"
attentions=[<enc_attention>, <img_attention>]
attention_state_size=5
use_sentinels=True
share_attn_projections=True

[decoder_hier_share_sentinel]
class=decoders.decoder.Decoder
name="decoder_hier_share_sentinel"
encoders=[<encoder>, <imagenet>]
attentions=[<hier_share_sentinel>]
rnn_size=2
embedding_size=3
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[hier_noshare_sentinel]
class=attention.combination.HierarchicalMultiAttention
name="wrapper_hns"
attentions=[<enc_attention>, <img_attention>]
attention_state_size=5
use_sentinels=True
share_attn_projections=False

[decoder_hier_noshare_sentinel]
class=decoders.decoder.Decoder
name="decoder_hier_noshare_sentinel"
encoders=[<encoder>, <imagenet>]
attentions=[<hier_noshare_sentinel>]
rnn_size=2
embedding_size=3
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[trainer]
; This block just fills the arguments of the trainer __init__ method.
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder_hier_noshare_nosentinel>,<decoder_hier_share_nosentinel>,<decoder_hier_share_sentinel>,<decoder_hier_noshare_sentinel>]
l2_weight=1.0e-8
clip_norm=1.0

[runner_hier_noshare_nosentinel]
class=runners.GreedyRunner
decoder=<decoder_hier_noshare_nosentinel>
output_series="target_hier_noshare_nosentinel"

[runner_hier_share_nosentinel]
class=runners.GreedyRunner
decoder=<decoder_hier_share_nosentinel>
output_series="target_hier_share_nosentinel"

[runner_hier_share_sentinel]
class=runners.GreedyRunner
decoder=<decoder_hier_share_sentinel>
output_series="target_hier_share_sentinel"

[runner_hier_noshare_sentinel]
class=runners.GreedyRunner
decoder=<decoder_hier_noshare_sentinel>
output_series="target_hier_noshare_sentinel"
