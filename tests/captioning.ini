[main]
name="Image Captioning"
tf_manager=<tf_manager>
output="tests/outputs/captioning"
overwrite_output_dir=True
batch_size=5
epochs=1
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner>]
postprocess=None
evaluation=[("target", evaluators.BLEU)]
logging_period=1
validation_period=2
test_datasets=[<val_data>,<val_data_no_target>]
random_seed=1234

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1

[image_reader]
class=readers.image_reader.imagenet_reader
prefix="tests/data/flickr30k"
target_width=224
target_height=224
vgg_normalization=True

[train_data]
class=dataset.load
series=["target", "images"]
data=["tests/data/flickr30k/train.en", ("tests/data/flickr30k/train_images.txt", <image_reader>)]

[val_data]
class=dataset.load
series=["target", "images"]
data=["tests/data/flickr30k/val.en", ("tests/data/flickr30k/val_images.txt", <image_reader>)]

[val_data_no_target]
class=dataset.load
series=["images"]
data=[("tests/data/flickr30k/train_images.txt", <image_reader>)]

[imagenet]
class=encoders.imagenet_encoder.ImageNet
name="imagenet_vgg"
data_id="images"
network_type="vgg_16"
spatial_layer="vgg_16/conv5/conv5_3"
slim_models_path="tests/tensorflow-models/research/slim"

[attention]
class=attention.Attention
state_size=10
name="attention_sentence_encoder"
encoder=<imagenet>

[decoder_vocabulary]
class=vocabulary.from_wordlist
path="tests/data/decoder_vocab.tsv"

[decoder]
class=decoders.decoder.Decoder
name="decoder"
encoders=[<imagenet>]
rnn_size=8
embedding_size=9
attentions=[<attention>]
dropout_keep_prob=0.5
data_id="target"
max_output_len=10
vocabulary=<decoder_vocabulary>

[trainer]
; This block just fills the arguments of the trainer __init__ method.
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
l2_weight=1.0e-8
clip_norm=1.0

[runner]
class=runners.GreedyRunner
decoder=<decoder>
output_series="target"
