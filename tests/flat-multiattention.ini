[main]
name="Configurations of Flat Attention Captioning"
tf_manager=<tf_manager>
output="tests/outputs/flat-multiattention"
overwrite_output_dir=True
batch_size=1
epochs=1
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner_flat_noshare_nosentinel>, <runner_flat_share_nosentinel>, <runner_flat_share_sentinel>, <runner_flat_noshare_sentinel>, <beam_runner_fss>]
postprocess=None
evaluation=[("target_flat_noshare_nosentinel", "target", evaluators.BLEU)]
logging_period=1
validation_period=5
test_datasets=[<val_data>]
random_seed=1234

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1

[numpy_reader]
class=readers.numpy_reader.from_file_list
prefix="tests/data/flickr30k"
shape=[8, 8, 2048]

[train_data]
class=dataset.load
series=["source", "target", "images"]
data=["tests/data/flickr30k/train.en", "tests/data/flickr30k/train.de", ("tests/data/flickr30k/train_images.npz.txt", <numpy_reader>)]

[val_data]
class=dataset.load
series=["source", "target", "images"]
data=["tests/data/flickr30k/val.en", "tests/data/flickr30k/val.de", ("tests/data/flickr30k/val_images.npz.txt", <numpy_reader>)]

[imagenet]
class=encoders.numpy_stateful_filler.SpatialFiller
input_shape=[8, 8, 2048]
data_id="images"

[encoder_vocabulary]
class=vocabulary.from_wordlist
path="tests/data/encoder_vocab.tsv"

[encoder]
class=encoders.recurrent.SentenceEncoder
name="sentence_encoder"
rnn_size=4
max_input_len=3
embedding_size=2
dropout_keep_prob=0.5
data_id="source"
vocabulary=<encoder_vocabulary>

[decoder_vocabulary]
class=vocabulary.from_wordlist
path="tests/data/decoder_vocab.tsv"

[flat_noshare_nosentinel]
class=attention.combination.FlatMultiAttention
name="wrapper_fnn"
encoders=[<encoder>, <imagenet>]
attention_state_size=5
use_sentinels=False
share_attn_projections=False

[decoder_flat_noshare_nosentinel]
class=decoders.decoder.Decoder
name="decoder_flat_noshare_nosentinel"
attentions=[<flat_noshare_nosentinel>]
encoders=[<encoder>, <imagenet>]
rnn_size=2
embedding_size=3
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[flat_share_nosentinel]
class=attention.combination.FlatMultiAttention
name="wrapper_fsn"
encoders=[<encoder>, <imagenet>]
attention_state_size=5
use_sentinels=False
share_attn_projections=True

[decoder_flat_share_nosentinel]
class=decoders.decoder.Decoder
name="decoder_flat_share_nosentinel"
attentions=[<flat_share_nosentinel>]
encoders=[<encoder>, <imagenet>]
rnn_size=2
embedding_size=3
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[flat_share_sentinel]
class=attention.combination.FlatMultiAttention
name="wrapper_fss"
encoders=[<encoder>, <imagenet>]
attention_state_size=5
use_sentinels=True
share_attn_projections=True

[decoder_flat_share_sentinel]
class=decoders.decoder.Decoder
name="decoder_flat_share_sentinel"
attentions=[<flat_share_sentinel>]
encoders=[<encoder>, <imagenet>]
rnn_size=2
embedding_size=3
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[flat_noshare_sentinel]
class=attention.combination.FlatMultiAttention
name="wrapper_fns"
encoders=[<encoder>, <imagenet>]
attention_state_size=5
use_sentinels=True
share_attn_projections=False

[decoder_flat_noshare_sentinel]
class=decoders.decoder.Decoder
name="decoder_flat_noshare_sentinel"
attentions=[<flat_noshare_sentinel>]
encoders=[<encoder>, <imagenet>]
rnn_size=2
embedding_size=3
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[beam_decoder_fss]
class=decoders.beam_search_decoder.BeamSearchDecoder
name="beam_search_decoder"
parent_decoder=<decoder_flat_share_sentinel>
beam_size=2
length_normalization=1.0
max_steps=3

[trainer]
; This block just fills the arguments of the trainer __init__ method.
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder_flat_noshare_nosentinel>,<decoder_flat_share_nosentinel>,<decoder_flat_share_sentinel>,<decoder_flat_noshare_sentinel>]
l2_weight=1.0e-8
clip_norm=1.0

[runner_flat_noshare_nosentinel]
class=runners.GreedyRunner
decoder=<decoder_flat_noshare_nosentinel>
output_series="target_flat_noshare_nosentinel"

[runner_flat_share_nosentinel]
class=runners.GreedyRunner
decoder=<decoder_flat_share_nosentinel>
output_series="target_flat_share_nosentinel"

[runner_flat_share_sentinel]
class=runners.GreedyRunner
decoder=<decoder_flat_share_sentinel>
output_series="target_flat_share_sentinel"

[runner_flat_noshare_sentinel]
class=runners.GreedyRunner
decoder=<decoder_flat_noshare_sentinel>
output_series="target_flat_noshare_sentinel"

[beam_runner_fss]
class=runners.BeamSearchRunner
output_series="target_fss_beam_2"
rank=2
decoder=<beam_decoder_fss>
