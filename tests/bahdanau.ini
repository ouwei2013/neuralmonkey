;; Small training test

[main]
name="translation bahdanau style"
tf_manager=<tf_manager>
output="tests/outputs/bahdanau"
overwrite_output_dir=True
batch_size=16
epochs=2
train_dataset=<train_data>
val_dataset=[<val_data>,<val_data>]
trainer=[<mt_trainer>, <greedy_trainer>]
runners=[<runner>, <representation_runner>, <debug_runner>]
postprocess=None
evaluation=[("target", evaluators.ROUGE_L), ("target", evaluators.SacreBLEU)]
logging_period=20
validation_period=60

test_datasets=[<val_data_no_target>]

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1

[batching]
class=dataset.BatchingScheme
bucket_boundaries=[5, 10, 15, 20]
bucket_batch_sizes=[20, 15, 10, 5, 2]

[train_data]
class=dataset.load
series=["source", "target"]
data=["tests/data/train.tc.en", "tests/data/train.tc.de"]
batching=<batching>

[val_data]
class=dataset.load
series=["source", "target"]
data=["tests/data/val.tc.en", "tests/data/val.tc.de"]
batching=<batching>

[val_data_no_target]
class=dataset.load
series=["source"]
data=["tests/data/val.tc.en"]
outputs=[("encoded", "tests/outputs/bahdanau/encoded"), ("debugtensors", "tests/outputs/bahdanau/debugtensors")]
batching=<batching>

[encoder_vocabulary]
class=vocabulary.from_wordlist
path="tests/data/encoder_vocab.tsv"

[encoder]
class=encoders.recurrent.SentenceEncoder
name="sentence_encoder"
rnn_size=7
max_input_len=10
embedding_size=11
data_id="source"
vocabulary=<encoder_vocabulary>

[attention]
class=attention.Attention
name="attention_sentence_encoder"
encoder=<encoder>

[decoder_vocabulary]
class=vocabulary.from_wordlist
path="tests/data/decoder_vocab.tsv"

[decoder]
class=decoders.decoder.Decoder
name="bahdanau_decoder"
encoders=[<encoder>]
rnn_size=8
embedding_size=9
attentions=[<attention>]
output_projection=<dec_maxout_output>
dropout_keep_prob=0.5
data_id="target"
max_output_len=10
vocabulary=<decoder_vocabulary>
supress_unk=True

[dec_maxout_output]
class=decoders.output_projection.maxout_output
maxout_size=7

[trainer1]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
l2_weight=1.0e-8
clip_norm=1.0

[trainer2]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]

[greedy_trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
clip_norm=10
l1_weight=0.0001

[mt_trainer]
class=trainers.multitask_trainer.MultitaskTrainer
trainers=[<trainer1>, <trainer1>, <trainer2>]

[runner]
; This block is used for both validation and testing to run the model on
; a given dataset.
class=runners.GreedyRunner
output_series="target"
decoder=<decoder>

[representation_runner]
class=runners.tensor_runner.RepresentationRunner
encoder=<encoder>
output_series="encoded"

[debug_runner]
class=runners.tensor_runner.TensorRunner
modelparts=[<encoder>, <encoder>, <decoder>]
tensors=["output", "temporal_states", "runtime_logits"]
batch_dims=[0, 0, 1]
; tensors_by_name=["sentence_encoder/input_to_final_state/Tensordot/add:0"]
tensors_by_name=[]
batch_dims_by_name=[]
output_series="debugtensors"
