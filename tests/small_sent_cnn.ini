[main]
name="translation"
tf_manager=<tf_manager>
output="tests/outputs/small_cnn_sent"
overwrite_output_dir=True
batch_size=16
epochs=2
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner>]
postprocess=None
evaluation=[("target", evaluators.BLEU), ("target", evaluators.TER)]
logging_period=20
validation_period=60
random_seed=1234

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1

[train_data]
class=dataset.load
series=["source", "target", "source_chars", "target_chars"]
data=["tests/data/train.tc.en", "tests/data/train.tc.de", (processors.helpers.preprocess_char_based, "source"), (processors.helpers.preprocess_char_based, "target")]

[val_data]
class=dataset.load
series=["source", "target", "source_chars", "target_chars"]
data=["tests/data/val.tc.en", "tests/data/val.tc.de", (processors.helpers.preprocess_char_based, "source"), (processors.helpers.preprocess_char_based, "target")]

[encoder_vocabulary]
class=vocabulary.from_wordlist
path="tests/data/str/vocab.tsv"

[encoder_input]
class=model.sequence.EmbeddedSequence
name="encoder_input"
embedding_size=11
max_length=10
data_id="source_chars"
vocabulary=<encoder_vocabulary>

[encoder]
class=encoders.SentenceCNNEncoder
name="sentence_encoder"
input_sequence=<encoder_input>
rnn_size=7
dropout_keep_prob=0.5
highway_depth=3
filters=[(1,13), (2,13), (3,13)]
segment_size=5

[attention]
class=attention.Attention
name="attention_sentence_encoder"
encoder=<encoder>

[decoder_vocabulary]
class=vocabulary.from_wordlist
path="tests/data/str/vocab.tsv"

[decoder]
class=decoders.Decoder
name="decoder"
encoders=[<encoder>]
rnn_size=8
embedding_size=9
attentions=[<attention>]
dropout_keep_prob=0.5
data_id="target_chars"
max_output_len=10
vocabulary=<decoder_vocabulary>

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
l2_weight=1.0e-8
clip_norm=1.0

[runner]
class=runners.GreedyRunner
decoder=<decoder>
output_series="target"
